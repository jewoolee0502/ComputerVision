{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNz5CVkBlmG+y8bIEEYIKzA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jewoolee0502/ComputerVision/blob/main/ECSE415_A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ECSE 415: Introduction to Computer Vision\n",
        "###### Jewoo Lee - 260910789\n",
        "###### Anthony Bonta - 261053688"
      ],
      "metadata": {
        "id": "iAzPZSvMwqs8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment 5: Video Analysis"
      ],
      "metadata": {
        "id": "1CuxHBzrwvP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Library Requirements"
      ],
      "metadata": {
        "id": "O_3pqgqmw7vk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz6zb0gpwXbw",
        "outputId": "b209583b-00e4-46c6-ea57-155ea9f6d240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Installs\n",
        "!pip install -q ultralytics\n",
        "!pip install -q ultralytics deep-sort-realtime\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Imports\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Path"
      ],
      "metadata": {
        "id": "Q1d94JUdw-tJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/' # jay's path\n",
        "# path = '' # anthony's path\n",
        "\n",
        "object_tracking_root = os.path.join(path, \"Object_Tracking\")"
      ],
      "metadata": {
        "id": "Xwnohvxfw-9B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Data Preparation"
      ],
      "metadata": {
        "id": "8V6aP8E-xBps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task1_images_dir = os.path.join(object_tracking_root, \"Task1\", \"images\")\n",
        "task1_video_path = os.path.join(object_tracking_root, \"task1_input.mp4\")\n",
        "\n",
        "print(\"Task1 images dir:\", task1_images_dir)\n",
        "print(\"Output video path:\", task1_video_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdEnjVrYxF3p",
        "outputId": "3ed9c639-c92c-4168-ac69-6c8554e7ef49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task1 images dir: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/Task1/images\n",
            "Output video path: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1_input.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FPS = 14 # given fps value\n",
        "\n",
        "def images_to_video(images_dir, output_path, fps):\n",
        "  # all images are .jpg\n",
        "  image_files = sorted(glob.glob(os.path.join(images_dir, \"*.jpg\")))\n",
        "  print(f\"Found {len(image_files)} images in {images_dir}\")\n",
        "\n",
        "  if len(image_files) == 0:\n",
        "    raise RuntimeError(f\"No .jpg image files found in {images_dir}\")\n",
        "\n",
        "  # read the first image and get its dimensions\n",
        "  first_img = cv2.imread(image_files[0])\n",
        "  height, width = first_img.shape[:2]\n",
        "  frame_size = (width, height)\n",
        "  print(f\"Target frame size: {frame_size}\")\n",
        "\n",
        "  # set up the video writer\n",
        "  fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "  writer = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n",
        "\n",
        "  if not writer.isOpened():\n",
        "    raise RuntimeError(f\"VideoWriter could not be opened for {output_path}\")\n",
        "\n",
        "  # write all images as frames\n",
        "  for idx, img_path in enumerate(image_files):\n",
        "    frame = cv2.imread(img_path)\n",
        "\n",
        "    if frame is None:\n",
        "      print(f\"Skipping unreadable image: {img_path}\")\n",
        "      continue\n",
        "\n",
        "    # resize every frame matches the first image's size\n",
        "    frame = cv2.resize(frame, frame_size)\n",
        "    writer.write(frame)\n",
        "\n",
        "  writer.release()\n",
        "  print(f\"Video saved to: {output_path}\")\n",
        "\n",
        "images_to_video(task1_images_dir, task1_video_path, FPS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBk9hhpbDPbU",
        "outputId": "c49ab220-2151-4122-d4d1-9ac7fed06505"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 429 images in /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/Task1/images\n",
            "Target frame size: (1920, 1080)\n",
            "Video saved to: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1_input.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Model Implementation"
      ],
      "metadata": {
        "id": "ujFwagwzxGYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conf_threshold = 0.3\n",
        "\n",
        "output_video_path = os.path.join(object_tracking_root, \"task1.mp4\")\n",
        "output_txt_path   = os.path.join(object_tracking_root, \"task1.txt\")\n",
        "\n",
        "print(\"Output video path:\", output_video_path)\n",
        "print(\"Output text path:\", output_txt_path)\n",
        "\n",
        "def draw_and_log_box(frame, frame_idx, track, txt_handle, color=(0, 0, 255)):\n",
        "    track_id = int(track.track_id)\n",
        "    x1, y1, x2, y2 = track.to_ltrb()\n",
        "\n",
        "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "    w = x2 - x1\n",
        "    h = y2 - y1\n",
        "\n",
        "    # draw bounding box\n",
        "    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "    # draw label slightly above the box\n",
        "    label_pos = (x1, max(0, y1 - 8))\n",
        "    cv2.putText(\n",
        "        frame,\n",
        "        f\"ID: {track_id}\",\n",
        "        label_pos,\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        0.5,\n",
        "        color,\n",
        "        2\n",
        "    )\n",
        "\n",
        "    # write tracking line\n",
        "    txt_handle.write(f\"{frame_idx},{track_id},{x1},{y1},{w},{h}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ldGwBJXxI6b",
        "outputId": "db4454b6-8c29-4068-c89a-27865064e18f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output video path: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1.mp4\n",
            "Output text path: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_model = YOLO(\"yolov8s.pt\")\n",
        "tracker = DeepSort(max_age=30, n_init=3, max_iou_distance=0.7)\n",
        "\n",
        "cap = cv2.VideoCapture(task1_video_path) # input video\n",
        "if not cap.isOpened():\n",
        "  raise RuntimeError(\"Cannot open video\")\n",
        "\n",
        "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "fps_val = cap.get(cv2.CAP_PROP_FPS)\n",
        "if fps_val <= 0:\n",
        "  fps_val = FPS\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "writer = cv2.VideoWriter(output_video_path, fourcc, fps_val, (w, h))\n",
        "\n",
        "txt_file = open(output_txt_path, \"w\")\n",
        "\n",
        "tracks_memory = []\n",
        "frame_idx = 1\n",
        "\n",
        "while True:\n",
        "  ok, frame = cap.read()\n",
        "  if not ok:\n",
        "    break\n",
        "\n",
        "  # run the YOLO model\n",
        "  det = yolo_model(frame, conf=conf_threshold, verbose=False)[0]\n",
        "\n",
        "  # convert YOLO detections into DeepSORT format\n",
        "  det_list = []\n",
        "  if det.boxes is not None:\n",
        "    for b in det.boxes:\n",
        "      cls_id = int(b.cls[0])\n",
        "      conf   = float(b.conf[0])\n",
        "      if cls_id != 0:\n",
        "        continue\n",
        "\n",
        "      x1, y1, x2, y2 = b.xyxy[0].tolist()\n",
        "      det_list.append(([x1, y1, x2 - x1, y2 - y1], conf, \"person\"))\n",
        "\n",
        "  # track\n",
        "  tracks = tracker.update_tracks(det_list, frame=frame)\n",
        "\n",
        "  # draw & log only confirmed tracks\n",
        "  for trk in tracks:\n",
        "    if not trk.is_confirmed():\n",
        "      continue\n",
        "\n",
        "    draw_and_log_box(frame, frame_idx, trk, txt_file)\n",
        "\n",
        "    # saving in memory\n",
        "    x1, y1, x2, y2 = trk.to_ltrb()\n",
        "    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "    tracks_memory.append((frame_idx, trk.track_id, x1, y1, x2 - x1, y2 - y1))\n",
        "\n",
        "  writer.write(frame)\n",
        "\n",
        "  if frame_idx % 50 == 0:\n",
        "    print(\"Processed:\", frame_idx)\n",
        "\n",
        "  frame_idx += 1\n",
        "\n",
        "cap.release()\n",
        "writer.release()\n",
        "txt_file.close()\n",
        "\n",
        "print(\"\\nCompleted!\")\n",
        "print(\"Video saved to:\", output_video_path)\n",
        "print(\"Text file saved to:\", output_txt_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE85p11G_2Fz",
        "outputId": "e9755f1b-4279-42ad-869e-7d86f3aaae6c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed: 50\n",
            "Processed: 100\n",
            "Processed: 150\n",
            "Processed: 200\n",
            "Processed: 250\n",
            "Processed: 300\n",
            "Processed: 350\n",
            "Processed: 400\n",
            "Completed!\n",
            "Video saved to: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1.mp4\n",
            "Text file saved to: /content/drive/MyDrive/McGill/2025/Fall 2025/ECSE 415/A5/Object_Tracking/task1.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Model Evaluation"
      ],
      "metadata": {
        "id": "GnFmDPAlxJi6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpMN0RS3xLM4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Prediction & Kaggle Competition"
      ],
      "metadata": {
        "id": "yQtzOFvLxLsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zi8R5N4rxPlo"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}